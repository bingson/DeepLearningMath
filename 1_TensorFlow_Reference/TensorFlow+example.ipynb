{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0, dtype=tf.float32)\n",
    "# So with this line above, initialize w to zero  \n",
    "# w is the parameter we're trying to optimize\n",
    "\n",
    "# cost = tf.add(tf.add(w**2, tf.multiply(-10.,w)),25)\n",
    "cost = w**2 - 10*w + 25\n",
    "\n",
    "# define a cost function\n",
    "# tensorflow knows how to take derivatives with respect to the add, multiply, \n",
    "# and squaring fn.\n",
    "\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "# define train to be our learning algo which uses a gradientDescentOptimizer \n",
    "# to min the cost function; we haven't run learning algo yet\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python \n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))\n",
    "```\n",
    "\n",
    "These three lines of code are quite idiomatic in TensorFlow, and what some programmers will do is use this alternative format. \n",
    "```Python\n",
    "with tf.Session() as session:\n",
    "    session.run(init)\n",
    "    print(session.run(w))\n",
    "```\n",
    "\n",
    "\n",
    "Which basically does the same thing. Set session to tf.Session() to start the session, and then use the session to run init, and then use the session to evaluate, say, w and then print the result.\n",
    "\n",
    "But this \n",
    "```Python \n",
    "with \n",
    "``` \n",
    "construction is used in a number of TensorFlow programs as well. It more or less means the same thing as the thing on the left. But the with command in Python is a little bit better at cleaning up in cases an error in exception while executing this inner loop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "session.run(train) # 1 - step of gradient descent\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.99999\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "w = tf.Variable(0, dtype=tf.float32)\n",
    "# So with this line above, initialize w to zero  \n",
    "# w is the parameter we're trying to optimize\n",
    "\n",
    "coefficients = np.array([[1.],[-10.], [25.]])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [3,1])\n",
    "# this placeholder function tells TensorFlow that x \n",
    "# is something that you provide the values for later. \n",
    "\n",
    "# cost = tf.add(tf.add(w**2, tf.multiply(-10.,w)),25)\n",
    "# cost = w**2 - 10*w + 25\n",
    "cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]\n",
    "\n",
    "# So now x becomes sort of like data that controls the \n",
    "# coefficients of this quadratic function. And this placeholder \n",
    "# function tells TensorFlow that x is something that you provide \n",
    "# the values for later. \n",
    "\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)\n",
    "# define train to be our learning algo which uses a gradientDescentOptimizer \n",
    "# to min the cost function; we haven't run learning algo yet\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# with loading coefficients into x as data\n",
    "session.run(train, feed_dict={x:coefficients})\n",
    "# 1 - step of gradient descent\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.99999\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    session.run(train, feed_dict={x:coefficients})\n",
    "print(session.run(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9838810047587611\n",
      "0.989527412793974\n",
      "0.927258042933603\n",
      "0.9761760806737537\n",
      "0.9058271100928854\n",
      "0.989129992995923\n",
      "0.9523987315602948\n",
      "0.9831912119882859\n",
      "0.9788968735980351\n",
      "0.9070256576687598\n",
      "0.9412010132184068\n",
      "0.9807803710675521\n",
      "0.9286853761038052\n",
      "0.9882731769336826\n",
      "0.919072972084993\n",
      "0.9564077758056667\n",
      "0.976338828334008\n",
      "0.9694533991001365\n",
      "0.9504558696781473\n",
      "0.9836158553220087\n",
      "0.9862626682575575\n",
      "0.9791312608798071\n",
      "0.9853117359575968\n",
      "0.9448611956887698\n",
      "0.9761060018004025\n",
      "0.9718250602890631\n",
      "0.9658349824460528\n",
      "0.9312003690224072\n",
      "0.9583984375652019\n",
      "0.9869134173762821\n",
      "0.989583183046205\n",
      "0.9772327571211478\n",
      "0.9687681429692582\n",
      "0.9813635819868785\n",
      "0.973096323901206\n",
      "0.9604227415167582\n",
      "0.9433715471481011\n",
      "0.9859420795116314\n",
      "0.9329722252637789\n",
      "0.9885021715027135\n",
      "0.9811661100004274\n",
      "0.9760171256022138\n",
      "0.9710510270319165\n",
      "0.921067900900932\n",
      "0.9693151466029013\n",
      "0.9688625601487324\n",
      "0.9094710988290715\n",
      "0.9324388368626045\n",
      "0.9751114333992348\n",
      "0.9843815796730185\n",
      "0.9129207892576203\n",
      "0.9661674924122444\n",
      "0.9873066130628986\n",
      "0.9577284731602613\n",
      "0.9399383010190515\n",
      "0.9795708213860115\n",
      "0.9860469582383382\n",
      "0.9683114602155682\n",
      "0.935525331329813\n",
      "0.978677877181405\n",
      "0.9855591204399449\n",
      "0.9353179650959133\n",
      "0.9631509560667637\n",
      "0.9805793543217395\n",
      "0.9732671702474281\n",
      "0.9328633726944352\n",
      "0.9802539590380859\n",
      "0.9794700785114422\n",
      "0.928085610667495\n",
      "0.9761508255689044\n",
      "0.9880174940073598\n",
      "0.9779412609210494\n",
      "0.9858851227571547\n",
      "0.965839495602853\n",
      "0.971148284758541\n",
      "0.9576054086094127\n",
      "0.9491050333506124\n",
      "0.987782317059469\n",
      "0.9534587079651167\n",
      "0.9544500329031151\n",
      "0.9701023177695139\n",
      "0.9855925062749988\n",
      "0.9575491730167325\n",
      "0.9736510686784875\n",
      "0.9825359438865867\n",
      "0.9790031621357299\n",
      "0.9427220914674955\n",
      "0.95787738002606\n",
      "0.9895857995507772\n",
      "0.9898155335042099\n",
      "0.95184410915891\n",
      "0.9788424800705819\n",
      "0.9848539210183158\n",
      "0.9837823063530705\n",
      "0.904795495590883\n",
      "0.967897194670973\n",
      "0.9787873637494092\n",
      "0.9626072669959058\n",
      "0.9894493920484836\n",
      "0.9822068399834945\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(100):\n",
    "    r = np.random.rand()\n",
    "    beta = 1-10**(- r - 1)\n",
    "    # beta = 1-10**(- r + 1)\n",
    "    # beta = r*0.09 + 0.9 \n",
    "    # beta = r*0.9 + 0.09 \n",
    "    \n",
    "    print(beta)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
