## 1_Initialization_Methods.ipynb

Different initializations lead to different results. By completing this assignment you will learn how to use different initializations to 
* speed up the convergence of gradient descent;
* increase the odds of gradient descent converging to a lower training (and generalization) error;
* break symmetry and make sure different hidden units can learn different things.

